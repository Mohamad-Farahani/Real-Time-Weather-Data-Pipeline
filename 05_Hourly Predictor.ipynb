{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbada25f-70b4-484f-9c65-49eeae8b1aa2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, unix_timestamp, hour, minute, current_timestamp\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "import datetime\n",
    "\n",
    "# 1. LOAD: Get only the last 1 hour of data from Silver\n",
    "# We filter based on the 'event_hub_time'\n",
    "one_hour_ago = datetime.datetime.now() - datetime.timedelta(hours=1)\n",
    "\n",
    "df_silver = spark.read.table(\"weather_silver_cleaned\") \\\n",
    "    .filter(col(\"event_hub_time\") >= one_hour_ago)\n",
    "\n",
    "# Check if we have enough data to train (need at least a few rows)\n",
    "if df_silver.count() < 5:\n",
    "    dbutils.notebook.exit(\"Not enough data to train yet. Waiting for more API calls...\")\n",
    "\n",
    "# 2. FEATURES: Extract Hour and Minute\n",
    "df_ml = df_silver.withColumn(\"h\", hour(col(\"event_hub_time\"))) \\\n",
    "                 .withColumn(\"m\", minute(col(\"event_hub_time\"))) \\\n",
    "                 .withColumn(\"ts\", unix_timestamp(col(\"event_hub_time\")))\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"ts\", \"h\", \"m\"], outputCol=\"features\")\n",
    "df_training = assembler.transform(df_ml).select(\"features\", col(\"temp_celsius\").alias(\"label\"))\n",
    "\n",
    "# 3. TRAIN: Fit the model on this hour's data\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "model = lr.fit(df_training)\n",
    "\n",
    "# 4. PREDICT: Calculate the timestamp for exactly 1 hour from now\n",
    "next_hour_ts = (datetime.datetime.now() + datetime.timedelta(hours=1))\n",
    "next_hour_unix = next_hour_ts.timestamp()\n",
    "\n",
    "# Prepare the future feature row\n",
    "future_data = spark.createDataFrame([(next_hour_unix, next_hour_ts.hour, next_hour_ts.minute)], [\"ts\", \"h\", \"m\"])\n",
    "future_features = assembler.transform(future_data)\n",
    "\n",
    "# Run Prediction\n",
    "prediction_df = model.transform(future_features)\n",
    "predicted_val = prediction_df.select(\"prediction\").collect()[0][0]\n",
    "\n",
    "# 5. SAVE: Store the prediction in a table to track accuracy later\n",
    "final_row = spark.createDataFrame([\n",
    "    (next_hour_ts, predicted_val, datetime.datetime.now())\n",
    "], [\"predicted_for_time\", \"predicted_temp\", \"calculated_at\"])\n",
    "\n",
    "final_row.write.format(\"delta\").mode(\"append\").saveAsTable(\"weather_predictions_history\")\n",
    "\n",
    "print(f\"Prediction for {next_hour_ts} is {predicted_val:.2f}Â°C. Logged to history.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05_Hourly Predictor",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
