{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcec80d1-9195-4bd5-b1be-dd3818a1d233",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, unix_timestamp\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# 1. Load the historical data from Silver\n",
    "df_silver = spark.read.table(\"weather_silver_cleaned\")\n",
    "\n",
    "# 2. Convert timestamp to a number (Unix seconds)\n",
    "df_ml = df_silver.withColumn(\"timestamp_num\", unix_timestamp(col(\"event_hub_time\")))\n",
    "\n",
    "# 3. Create a 'Feature' vector (Spark ML requires this)\n",
    "assembler = VectorAssembler(inputCols=[\"timestamp_num\"], outputCol=\"features\")\n",
    "df_final = assembler.transform(df_ml).select(\"features\", col(\"temp_celsius\").alias(\"label\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c525465-be0f-473e-939b-9b8f17521d15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create the Linear Regression object\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "# Fit the model (This is the 'training' phase)\n",
    "model = lr.fit(df_final)\n",
    "\n",
    "print(f\"Model Trained. Intercept: {model.intercept}, Coefficient: {model.coefficients[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7a5d6c7-4020-4465-ba5d-8dd33d91521a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# 1. Get the timestamp for exactly 24 hours from now\n",
    "tomorrow_date = datetime.datetime.now() + datetime.timedelta(days=1)\n",
    "tomorrow_unix = tomorrow_date.timestamp()\n",
    "\n",
    "# 2. Create a small DataFrame for this future point\n",
    "future_df = spark.createDataFrame([(tomorrow_unix,)], [\"timestamp_num\"])\n",
    "future_vec = assembler.transform(future_df)\n",
    "\n",
    "# 3. Predict!\n",
    "prediction = model.transform(future_vec)\n",
    "predicted_temp = prediction.select(\"prediction\").collect()[0][0]\n",
    "\n",
    "print(f\"The predicted temperature for London tomorrow ({tomorrow_date.strftime('%Y-%m-%d')}) is: {predicted_temp:.2f}Â°C\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_Weather_Prediction",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
